# gpu config
accelerator: gpu
devices: [6]

# log config
log_dir: ./log
resume: null  # if want to resume, specify ckpt path

# inference config
ckpt_path: /disk3/hyyan/project/ad_hoc/ABNet/log/ckpts/version_0/epoch=83-step=268295-pesq=2.94.ckpt

# dataset config
dataset_config:
  batch_size: 4
  cut_len: 64000  # length of training samples: 4s
  num_workers: 2  # dataloader workers
  train_src_dir: /disk3/hyyan/dataset/ad_hoc/train/noisy
  train_tgt_dir: /disk3/hyyan/dataset/ad_hoc/train/reverb_clean
  val_src_dir: /disk3/hyyan/dataset/ad_hoc/val/noisy
  val_tgt_dir: /disk3/hyyan/dataset/ad_hoc/val/reverb_clean
  test_src_dir: /disk3/hyyan/dataset/ad_hoc/test/noisy
  test_tgt_dir: /disk3/hyyan/dataset/ad_hoc/test/reverb_clean


# training config
max_epochs: 100
val_check_interval: 1.0  # validate every 0.5 epochs
gradient_clip_val: 5.0
g_opt:
  lr: 5.0e-4
  betas: [0.8, 0.99]
d_opt:
  lr: 5.0e-4
  betas: [0.8, 0.99]
g_sch:
  step_size: 1
  gamma: 0.98
  verbose: true
d_sch:
  step_size: 1
  gamma: 0.98
  verbose: true

# model config and loss weights
model_config:
  num_channels: 16
  n_fft: 512
  hop_length: 256
  compress_factor: 0.3
weights:
  complex: 0.1
  mag: 0.9
  adv: 0.05
